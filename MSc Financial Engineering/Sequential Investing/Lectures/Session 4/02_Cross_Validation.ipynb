{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Cross-Validation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_test](/Users/marioht/Dropbox/EDHEC/2022/COURSES/S2/Prediction_&_Sequential_Investment_Strategies/Presentations/2nd_FINAL/train_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overfitting](/Users/marioht/Dropbox/EDHEC/2022/COURSES/S2/Prediction_&_Sequential_Investment_Strategies/Presentations/2nd_FINAL/train_validation_holdout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list(range(1, 11))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's CV functionality can be imported from sklearn.model_selection.\n",
    "For a single split of your data into a training and a test set, use `train_test_split`, where the shuffle parameter, by default, ensures the randomized selection of observations. You\n",
    "can ensure replicability by seeding the random number generator by setting `random_state`. There is also a `stratify` parameter, which ensures for a classification problem that the train and test sets will contain approximately the same proportion of each class. The result looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (train_test_split, \n",
    "                                     KFold, \n",
    "                                     LeaveOneOut,\n",
    "                                     LeavePOut, \n",
    "                                     ShuffleSplit,\n",
    "                                     TimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 4, 6, 7, 2, 3, 9, 1], [10, 5]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(data, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we train a model using all data except row numbers 8 and 9, which will be used to generate predictions and measure the errors given on the known labels. This method is useful for quick evaluation but is sensitive to the split, and the standard error of the performance measure estimate will be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `KFold` iterator produces several disjunct splits and assigns each of these splits once to the validation set, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "for train, validate in kf.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the number of splits, most CV objects take a `shuffle` argument that ensures randomization. To render results reproducible, set the random_state as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for train, validate in kf.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original CV implementation used a __leave-one-out method__ that used each observation once as the validation set, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9] [0]\n",
      "[0 2 3 4 5 6 7 8 9] [1]\n",
      "[0 1 3 4 5 6 7 8 9] [2]\n",
      "[0 1 2 4 5 6 7 8 9] [3]\n",
      "[0 1 2 3 5 6 7 8 9] [4]\n",
      "[0 1 2 3 4 6 7 8 9] [5]\n",
      "[0 1 2 3 4 5 7 8 9] [6]\n",
      "[0 1 2 3 4 5 6 8 9] [7]\n",
      "[0 1 2 3 4 5 6 7 9] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "for train, validate in loo.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maximizes the number of models that are trained, which increases computational costs. While the validation sets do not overlap, the overlap of training sets is maximized, driving up the correlation of models and their prediction errors. As a result, the variance of the prediction error is higher for a model with a larger number of folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-P-Out CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar version to leave-one-out CV is leave-P-out CV, which generates all possible combinations of p data rows, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6 7 8 9] [0 1]\n",
      "[1 3 4 5 6 7 8 9] [0 2]\n",
      "[1 2 4 5 6 7 8 9] [0 3]\n",
      "[1 2 3 5 6 7 8 9] [0 4]\n",
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "[1 2 3 4 5 7 8 9] [0 6]\n",
      "[1 2 3 4 5 6 8 9] [0 7]\n",
      "[1 2 3 4 5 6 7 9] [0 8]\n",
      "[1 2 3 4 5 6 7 8] [0 9]\n",
      "[0 3 4 5 6 7 8 9] [1 2]\n",
      "[0 2 4 5 6 7 8 9] [1 3]\n",
      "[0 2 3 5 6 7 8 9] [1 4]\n",
      "[0 2 3 4 6 7 8 9] [1 5]\n",
      "[0 2 3 4 5 7 8 9] [1 6]\n",
      "[0 2 3 4 5 6 8 9] [1 7]\n",
      "[0 2 3 4 5 6 7 9] [1 8]\n",
      "[0 2 3 4 5 6 7 8] [1 9]\n",
      "[0 1 4 5 6 7 8 9] [2 3]\n",
      "[0 1 3 5 6 7 8 9] [2 4]\n",
      "[0 1 3 4 6 7 8 9] [2 5]\n",
      "[0 1 3 4 5 7 8 9] [2 6]\n",
      "[0 1 3 4 5 6 8 9] [2 7]\n",
      "[0 1 3 4 5 6 7 9] [2 8]\n",
      "[0 1 3 4 5 6 7 8] [2 9]\n",
      "[0 1 2 5 6 7 8 9] [3 4]\n",
      "[0 1 2 4 6 7 8 9] [3 5]\n",
      "[0 1 2 4 5 7 8 9] [3 6]\n",
      "[0 1 2 4 5 6 8 9] [3 7]\n",
      "[0 1 2 4 5 6 7 9] [3 8]\n",
      "[0 1 2 4 5 6 7 8] [3 9]\n",
      "[0 1 2 3 6 7 8 9] [4 5]\n",
      "[0 1 2 3 5 7 8 9] [4 6]\n",
      "[0 1 2 3 5 6 8 9] [4 7]\n",
      "[0 1 2 3 5 6 7 9] [4 8]\n",
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "[0 1 2 3 4 7 8 9] [5 6]\n",
      "[0 1 2 3 4 6 8 9] [5 7]\n",
      "[0 1 2 3 4 6 7 9] [5 8]\n",
      "[0 1 2 3 4 6 7 8] [5 9]\n",
      "[0 1 2 3 4 5 8 9] [6 7]\n",
      "[0 1 2 3 4 5 7 9] [6 8]\n",
      "[0 1 2 3 4 5 7 8] [6 9]\n",
      "[0 1 2 3 4 5 6 9] [7 8]\n",
      "[0 1 2 3 4 5 6 8] [7 9]\n",
      "[0 1 2 3 4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "lpo = LeavePOut(p = 2)\n",
    "for train, validate in lpo.split(data):\n",
    "    print(train, validate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ShuffleSplit` class creates independent splits with potentially overlapping validation sets, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 7 2 9 4 3 6] [8 1]\n",
      "[8 5 3 4 7 9 6 2] [0 1]\n",
      "[0 6 8 5 3 7 1 4] [9 2]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits = 3, test_size = 2, random_state = 42)\n",
    "for train, validate in ss.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges with cross-validation in finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key assumption for the cross-validation methods discussed so far is the IID distribution of the samples available for training.\n",
    "For financial data, this is often not the case. On the contrary, financial data is neither independently nor identically distributed because of serial correlation and time-varying standard deviation, also known as heteroskedasticity. `TimeSeriesSplit` in the `sklearn.model_selection` module aims to address the linear order of time-series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time-series nature of the data implies that cross-validation produces a situation where data from the future will be used to predict data from the past. This is unrealistic at best and data snooping at worst, to the extent that future data reflects past events.\n",
    "To address time dependency, the `TimeSeriesSplit` object implements a walk-forward test with an expanding training set, where subsequent training sets are supersets of past training sets, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [5]\n",
      "[0 1 2 3 4 5] [6]\n",
      "[0 1 2 3 4 5 6] [7]\n",
      "[0 1 2 3 4 5 6 7] [8]\n",
      "[0 1 2 3 4 5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "for train, validate in tscv.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `max_train_size` parameter to implement walk-forward cross-validation, where the size of the training set remains constant over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4] [5]\n",
      "[2 3 4 5] [6]\n",
      "[3 4 5 6] [7]\n",
      "[4 5 6 7] [8]\n",
      "[5 6 7 8] [9]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 5, max_train_size = 4)\n",
    "for train, validate in tscv.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [4 5]\n",
      "[2 3 4 5] [6 7]\n",
      "[4 5 6 7] [8 9]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 3, max_train_size = 4, test_size = 2)\n",
    "for train, validate in tscv.split(data):\n",
    "    print(train, validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`End of File`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9b81f9577295172555c798b308f48b2cfbfb99e58c56d13066ae25b3f1aa1fd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
