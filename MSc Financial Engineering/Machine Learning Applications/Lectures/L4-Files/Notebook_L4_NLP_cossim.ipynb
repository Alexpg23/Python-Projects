{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa675aac",
   "metadata": {},
   "source": [
    "# Objective: compute cosine similarity when documents are represented with two different approaches: 1) BoW representation and 2)TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2061e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6251760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus documents\n",
    "Doc_1='the best deep learning course'\n",
    "Doc_2='deep learning is easy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190546c3",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b5be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20af93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'best': 0, 'deep': 2, 'learning': 5, 'course': 1, 'is': 4, 'easy': 3}\n",
      "\n",
      "\n",
      "  (0, 6)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "\n",
      "\n",
      "[[1 1 1 0 0 1 1]\n",
      " [0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, build vocabulary and transform each document into a bag of words matrix\n",
    "count_matrix = count_vectorizer.fit_transform([Doc_1,Doc_2])\n",
    "\n",
    "# Vocabulary in the corpus\n",
    "vocabulary=count_vectorizer.vocabulary_\n",
    "\n",
    "# Bag of words vector for each document\n",
    "bag=count_matrix.toarray()\n",
    "\n",
    "print(vocabulary)\n",
    "print(\"\\n\")\n",
    "print(count_matrix)\n",
    "print(\"\\n\")\n",
    "print(bag)\n",
    "\n",
    "# Remark: The ordering of the actual words in the sentences has been lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be99e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8addaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bag[0,:]).reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4ecf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4472136]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between doc 1 and doc 2 calculation. reshape (1,-1) is used to specify \n",
    "# bag[0,:] and bag[1,:] as 2D matrices with 1 row and avoid error message\n",
    "cosine_similarity(bag[0,:].reshape(1, -1) , bag[1,:].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d22796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4472135954999579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison with calculation in the slides\n",
    "1/np.sqrt(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc82eb3",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4125bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc415a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'best': 0, 'deep': 2, 'learning': 5, 'course': 1, 'is': 4, 'easy': 3}\n",
      "\n",
      "\n",
      "  (0, 1)\t1.4054651081081644\n",
      "  (0, 5)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 0)\t1.4054651081081644\n",
      "  (0, 6)\t1.4054651081081644\n",
      "  (1, 3)\t1.4054651081081644\n",
      "  (1, 4)\t1.4054651081081644\n",
      "  (1, 5)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "\n",
      "\n",
      "[[1.40546511 1.40546511 1.         0.         0.         1.\n",
      "  1.40546511]\n",
      " [0.         0.         1.         1.40546511 1.40546511 1.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize, build vocabulary and transform each document into a tf-idf matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([Doc_1,Doc_2])\n",
    "\n",
    "# Vocabulary in the corpus\n",
    "vocabulary = tfidf_vectorizer.vocabulary_\n",
    "\n",
    "# Tf_idf vector for each document\n",
    "matrix = tfidf_matrix .toarray()\n",
    "\n",
    "print(vocabulary)\n",
    "print(\"\\n\")\n",
    "print(tfidf_matrix)\n",
    "print(\"\\n\")\n",
    "print(matrix)\n",
    "\n",
    "# Remark: The ordering of the actual words in the sentences has been lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e3d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29121942]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between doc 1 and doc 2 calculation. reshape (1,-1) is used to specify \n",
    "# bag[0,:] and bag[1,:] as 2D matrices with 1 row and avoid error message\n",
    "cosine_similarity(tfidf_matrix[0,:].reshape(1, -1) , tfidf_matrix[1,:].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0773a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'best': 0, 'deep': 2, 'learning': 5, 'course': 1, 'is': 4, 'easy': 3}\n",
      "\n",
      "\n",
      "  (0, 1)\t0.4992213265230509\n",
      "  (0, 5)\t0.35520008546852583\n",
      "  (0, 2)\t0.35520008546852583\n",
      "  (0, 0)\t0.4992213265230509\n",
      "  (0, 6)\t0.4992213265230509\n",
      "  (1, 3)\t0.5761523551647353\n",
      "  (1, 4)\t0.5761523551647353\n",
      "  (1, 5)\t0.40993714596036396\n",
      "  (1, 2)\t0.40993714596036396\n",
      "\n",
      "\n",
      "[[0.49922133 0.49922133 0.35520009 0.         0.         0.35520009\n",
      "  0.49922133]\n",
      " [0.         0.         0.40993715 0.57615236 0.57615236 0.40993715\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Remark: by default the TfidfVectorizer has the parameter norm set to l2 to account for the length of a document\n",
    "# When we use TF-IDF representation to compute cosine similarity between 2 words, has it an impact?\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(norm='l2')\n",
    "# Tokenize, build vocabulary and transform each document into a tf-idf matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([Doc_1,Doc_2])\n",
    "\n",
    "# Vocabulary in the corpus\n",
    "vocabulary = tfidf_vectorizer.vocabulary_\n",
    "\n",
    "# Tf_idf vector for each document\n",
    "matrix = tfidf_matrix .toarray()\n",
    "\n",
    "print(vocabulary)\n",
    "print(\"\\n\")\n",
    "print(tfidf_matrix)\n",
    "print(\"\\n\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81fac0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29121942]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between doc 1 and doc 2 calculation. reshape (1,-1) is used to specify \n",
    "# bag[0,:] and bag[1,:] as 2D matrices with 1 row and avoid error message\n",
    "cosine_similarity(tfidf_matrix[0,:].reshape(1, -1) , tfidf_matrix[1,:].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a93cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
