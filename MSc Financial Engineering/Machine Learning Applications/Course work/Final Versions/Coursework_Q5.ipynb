{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea80299d-aaae-4bf4-adfa-8737f6c10167",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485d8139-0da4-4759-a5e1-a48b21b44b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ea6c86-aab0-4364-bcfd-c3e43d0002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d6131-b7e9-487c-b620-262a6fcadc55",
   "metadata": {},
   "source": [
    "### 5.1 We start by loading the dataset and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebd5b18-5783-4003-bdc0-748670410417",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a54ee-07ab-4a83-8faf-bf0b8efb6fb0",
   "metadata": {},
   "source": [
    "Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a92976e-61a9-44cf-ae4c-f64eab27bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0724e-b586-4be2-ab88-6c2e0ed47ef4",
   "metadata": {},
   "source": [
    "Resampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a768542-ac3e-426f-a7d2-e283f250cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s, x_test_s = x_train.reshape(60000, 784) / 255, x_test.reshape(10000, 784) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba54f3d-6533-494b-a5fd-7a9f8c140dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfd6442-5b15-4078-aedf-5d00738a1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_s[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551e7ac1-d52d-451f-9f78-5fef53a63cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389cbeed-668c-4216-ada7-0682a961838e",
   "metadata": {},
   "source": [
    "### 5.2 Now we create an Autoencoder with a structure [400, 200, 100, 50, N, 50, 100, 200, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345121d-de32-4e35-bc63-8b8d3f14ebca",
   "metadata": {},
   "source": [
    "N will be looped through [50, 25, 10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70200e41-4394-44e4-b75d-369069b995ae",
   "metadata": {},
   "source": [
    "We will do this by creating a looping function that outputs the Autoencoder model.\n",
    "\n",
    "For this reconstruction model, we wil use:\n",
    "\n",
    "- Sigmoid activation in the output layer (last layer in decoder)\n",
    "- Loss function: Mean Squared Error\n",
    "- Metric: Loss of the validation set\n",
    "\n",
    "We chose to use MSE + val_loss for it responded better to the model in comparison to Binary Crossentropy + Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "005667e3-f756-4d68-8c8c-3a679c537f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the autoencoder function\n",
    "def build_autoencoder(N):\n",
    "\n",
    "    encoder = Sequential()\n",
    "    encoder.add(Dense(400,  activation='relu', input_shape=(784,)))\n",
    "    encoder.add(Dense(200,  activation='relu'))\n",
    "    encoder.add(Dense(100,  activation='relu'))\n",
    "    encoder.add(Dense(50,   activation='relu'))\n",
    "    encoder.add(Dense(N,   activation='relu')) # Bottleneck\n",
    "\n",
    "    decoder = Sequential()\n",
    "    decoder.add(Dense(50,  input_shape=[N], activation='relu'))\n",
    "    decoder.add(Dense(100,  activation='relu'))\n",
    "    decoder.add(Dense(200,  activation='relu'))\n",
    "    decoder.add(Dense(400,  activation='relu'))\n",
    "    decoder.add(Dense(784,  activation='sigmoid'))\n",
    "    \n",
    "    autoencoder = Sequential([encoder, decoder])\n",
    "    \n",
    "    autoencoder.compile(loss='MSE', optimizer = Adam())\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec75841a-44ea-4190-bd66-795f31318163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a results DataFrame to store the validation loss on the test set \n",
    "results = pd.DataFrame(index=['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373449c7-610d-4199-b625-b039a26818a4",
   "metadata": {},
   "source": [
    "Now we will loop through the desired values of N and store the accuracy of each in our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3d2eb5-5a9b-47b2-8a6d-391a53affb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0909 - val_loss: 0.0683\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 2s 27ms/step - loss: 0.0623 - val_loss: 0.0557\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.0476 - val_loss: 0.0406\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.0374 - val_loss: 0.0339\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.0320 - val_loss: 0.0298\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0287 - val_loss: 0.0278\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.0264 - val_loss: 0.0252\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0247 - val_loss: 0.0237\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0234 - val_loss: 0.0231\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 2s 29ms/step - loss: 0.0223 - val_loss: 0.0214\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 3s 32ms/step - loss: 0.0935 - val_loss: 0.0685\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 2s 28ms/step - loss: 0.0622 - val_loss: 0.0560\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0505 - val_loss: 0.0433\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0406 - val_loss: 0.0377\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0358 - val_loss: 0.0329\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0324 - val_loss: 0.0306\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0300 - val_loss: 0.0292\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 2s 36ms/step - loss: 0.0279 - val_loss: 0.0267\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0243 - val_loss: 0.0234\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 3s 34ms/step - loss: 0.1024 - val_loss: 0.0725\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0685 - val_loss: 0.0648\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0612 - val_loss: 0.0548\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0518 - val_loss: 0.0485\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0470 - val_loss: 0.0453\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0440 - val_loss: 0.0427\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0415 - val_loss: 0.0392\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0378 - val_loss: 0.0372\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0357 - val_loss: 0.0347\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0345 - val_loss: 0.0338\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 3s 35ms/step - loss: 0.0979 - val_loss: 0.0718\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0673 - val_loss: 0.0645\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0622 - val_loss: 0.0576\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0551 - val_loss: 0.0513\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0489 - val_loss: 0.0464\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0452 - val_loss: 0.0435\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0429 - val_loss: 0.0417\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0413 - val_loss: 0.0405\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0401 - val_loss: 0.0396\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0391 - val_loss: 0.0387\n"
     ]
    }
   ],
   "source": [
    "# We use x_train_s as both input and output data, since the autoencoder is recreating the initial images\n",
    "for n in [50, 25, 10, 5]:\n",
    "    trained_model = build_autoencoder(n).fit(x_train_s, x_train_s, batch_size=1024, \n",
    "                                epochs=10, verbose=1, \n",
    "                                validation_data=(x_test_s, x_test_s))\n",
    "    results[n] = trained_model.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0bf119-3266-473d-8ff7-a6ee59cdfe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>25</th>\n",
       "      <th>10</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_accuracy</th>\n",
       "      <td>0.021365</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>0.03868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    50       25        10       5 \n",
       "val_accuracy  0.021365  0.02344  0.033793  0.03868"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f771fae-0a16-4550-9b4a-8f435aaf813a",
   "metadata": {},
   "source": [
    "### Results interpretation\n",
    "##### Observing the results in the DataFrame, as we decrease the number of nodes in the Bottleneck layer the loss on the validation data goes up. This makes sense since the more we reduce the dimension of the initial images, the more we loose information and, therefore, performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1705d-9f4d-4248-996f-293ea75daca5",
   "metadata": {},
   "source": [
    "### 5.3 - Generating a non-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c6625-3c6f-42a4-ad76-8e22ed1c02b4",
   "metadata": {},
   "source": [
    "Now we will pass an image that is completely different from the ones in the MNIST dataset. We will try to reconstruct this image using our build_autoencoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c6387e-ea71-449c-9850-3782111af367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 3s 36ms/step - loss: 0.0942 - val_loss: 0.0687\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0637 - val_loss: 0.0586\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0519 - val_loss: 0.0449\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0395 - val_loss: 0.0355\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 2s 30ms/step - loss: 0.0336 - val_loss: 0.0310\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 2s 34ms/step - loss: 0.0299 - val_loss: 0.0284\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0273 - val_loss: 0.0259\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0254 - val_loss: 0.0245\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 2s 31ms/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 2s 32ms/step - loss: 0.0220 - val_loss: 0.0210\n"
     ]
    }
   ],
   "source": [
    "# We build and fit our model using N = 50, for maximum performance\n",
    "trained_model = build_autoencoder(50).fit(x_train_s, x_train_s, batch_size=1024, \n",
    "                                epochs=10, verbose=1, \n",
    "                                validation_data=(x_test_s, x_test_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5279d706-36eb-45bb-85ff-a41d5877944d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2545.8208]\n"
     ]
    }
   ],
   "source": [
    "# We pass in an image of the letter W in the correct format for this exercise\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"img_Q52.png\", target_size=(28, 28), \n",
    "                     color_mode = \"grayscale\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Now we use our build_autoencoder function to try and predict the passed image\n",
    "input_img = image.img_to_array(img)\n",
    "inputs = input_img.reshape(1,784)\n",
    "target_data = trained_model.model.predict(inputs)\n",
    "plt.imshow(target_data.reshape(28,28))\n",
    "plt.show()\n",
    "\n",
    "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1238f5f-f3e4-464b-b06c-d5e32bd926dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5737.8027]\n"
     ]
    }
   ],
   "source": [
    "# We pass in an image of the letter V in the correct format for this exercise\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = image.load_img(\"img_Q5.png\", target_size=(28, 28), \n",
    "                     color_mode = \"grayscale\")\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Now we use our build_autoencoder function to try and predict the passed image\n",
    "input_img = image.img_to_array(img)\n",
    "inputs = input_img.reshape(1,784)\n",
    "target_data = trained_model.model.predict(inputs)\n",
    "plt.imshow(target_data.reshape(28,28))\n",
    "plt.show()\n",
    "\n",
    "dist = np.linalg.norm(inputs - target_data, axis=-1)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287c683-e9da-433f-82f1-ccfe03c74f68",
   "metadata": {},
   "source": [
    "### Results interpretation\n",
    "##### As expected, the model fails when it encounters an image that it does not know. This is an important feature of the autoencoder, we can use this to detect anomalies in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbb457-b532-4ee1-8f32-e0b15aaa1724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
